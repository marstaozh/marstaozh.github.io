## Kafka急速入门

### 1. Producer

```java
// 1. 配置生产者参数属性和创建生产者对象

// 配置生产者启动的关键属性参数
Properties properties = new Properties();

// BOOTSTRAP_SERVERS_CONFIG -> 连接Kafka集群的服务列表，如果有多个，使用","进行分割
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.1.31：9092");

// CLIENT_ID_CONFIG -> 这个属性的目的是标记KafkaClient的ID
properties.put(ProducerConfig.CLIENT_ID_CONFIG, "quickstart-producer");
/**
*	KEY_SERIALIZER_CLASS_CONFIG VALUE_SERIALIZER_CLASS_CONFIG
*	Q: 对kafka的key和value做序列化，为什么需要序列化？
*	A: 因为Kafka Broker在接受消息的时候，必须要以二进制的方式接收，所以必须对KEY和VALUE进行序列化
*	字符串序列化类：org.apache.kafka.common.serialization.StringSerializer
*/
// KEY: 是kafka用于做消息投递时，计算出投递到具体对应主题的哪一个分区(partition)而需要的
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

// VALUE: 实际发送消息的内容
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

// 2. 构建消息：ProducerRecord

// 创建Kafka生产者对象，传递properties属性参数集合
KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
//																			topic↓				实际消息内容↓
ProducerRecord<String, String> record = new ProducerRecord<String, String>("test-quickstart", "messageDetail")

// 3. 发送消息：send
producer.send(record);
// 4. 关闭生产者
producer.close();
```



### 2. Counsumer

```java
// 1. 配置消费者参数属性和构建消费者对象

// 配置消费者启动的关键属性参数
Properties properties = new Properties();
// BOOTSTRAP_SERVERS_CONFIG -> 连接Kafka集群的服务列表，如果有多个，使用","进行分割
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.1.31：9092");

// KEY VALUE的反序列化
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

// 非常重要的配置：与消费者订阅组有关系
properties.put(ConsumerConfig.GROUP_ID_CONFIG, "quickstart-group");
// 常规属性：绘画连接超时事件
properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 500);
// 消费者提交offset：自动提交or手工提交，默认时自动提交
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);

// 创建Kafka消费者对象，传递properties属性参数集合
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);

// 2. 订阅主题
consumer.subscribe(Collections.singletonList("test-quickstart"));
    
// 3. 拉取消息
while(true) {
    // 等待多久拉取一次消息 -> Duration.ofMillis(1000)
    // 拉取主题中所有的partition，即拉取所有的消息
    ConsumerRecords<Strin g, String> records = consumer.poll(Duration.ofMillis(1000));
    // 遍历所有的partition，以获取每个partition中的所有消息
    for(TopicPartition topicPartition : records.partitions()) {
        
        List<ConsumerRecord<String, String>> partitionRecords = records.records(topicPartition);
        consumerRecords.forEach(consumerRecord -> {
            long offset = consumerRecord.offset();
            String key = consumerRecord.key();
            String value = consumerRecord.value();
            System.out.println(String.format("收到主题：%s, 分区号：%s, offset：%s, 消息key：%s, 消息内容：%s",
            	TopicConstant.QUIT_START_TOPIC, topicPartition.partition(), offset, key, value));
		});
    }
}
    
// 4. 提交消费偏移量，关闭消费者
```

