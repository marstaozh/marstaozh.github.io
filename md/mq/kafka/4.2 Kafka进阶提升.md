##  Kafka进阶提升

### 1. 生产者

#### 1.1 生产者核心知识

#### 1.2 生产者重要参数详解

```
· acks：指定发送消息后，Broker端至少又多少个副本接收到该消息；默认acks=1；
	acks=1：只要leader副本接收到消息后，就会收到来自服务端的成功响应
	acks=0：生产者发送消息后，不需要等待任务服务端的响应
	acks=-1/all：生产者在消息发送之后，需要等待ISR中的所有副本都成功写入消息后，才能够收到来自服务端的成功响应

acks面试题：
1. Q：说一下acks的3个取值代表什么含义，分别适用于什么样的应用场景？
2. Q：acks=-1 or acks=all 是不是一定就能够保障消息的可靠性呢？
	Tips：min.insync.replicas = 2
	
· max.request.size: 该参数用来限制生产者客户端能发送消息的最大值，默认1M
· retries: 重试次数，默认为1
· retry.backoff.msretries：重试间隔，默认为100ms
· compression.type: 这个参数用来指定消息的压缩方式，默认值为"none"，可选配置："gzip" "snappy" "lz4"
· connections.max.idle.ms: 这个参数用来指定在多久之后关闭限制的连接，默认值是540000ms，即9分钟
· linger.ms: 这个参数用来指定生产者发送ProducerBatch之前等待更多消息(ProducerRecord)加入ProducerBatch的时间，默认值为0
· batch.size: 累计多少条消息，则一次进行批量发送
· buffer.memory: 缓存提升性能参数，默认为32M
· receive.buffer.bytes: 这个参数用来设置Socket接收消息缓冲区(SO_RECBUF)的大小，默认值为32768B，即32KB
· send.buffer.bytes: 这个参数用来设置Socket发送消息缓冲区(SO_SNDBUF)的大小，默认值为131072B，即128KB
· request.timeout.ms: 这个参数用来配置Producer等待请求响应的最长时间，默认值为30000ms
```

#### 1.3 生产者拦截器

```java
· 拦截器（interceptor）：Kafka对应着有生产者和消费者两种拦截器
· 生产者实现接口：org.apache.kafka.clients.producer.ProducerInterceptor
// 添加生产者的拦截器属性
properties.put(ProducerConfig.INTERCEPTOR_CLASS_CONFIG, 生产者拦截器.class.getName());


· 消费者实现接口：org.apache.kafka.clients.consumer.ConsumerInterceptor
// 添加生产者的拦截器属性
properties.put(ConsumerConfig.INTERCEPTOR_CLASS_CONFIG, 消费者拦截器.class.getName());

```

#### 1.4 序列化反序列化

```
· 序列化与饭序列化：生产者需要用序列化器(Serializer)把对象转成字节数组才能通过网络发送给Kafka; 而在对策，消费者需要用反序列化器(Deserializer)把从Kafka中收到的字节数组转成相应的对象。
· 序列化接口：org.apache.kafka.common.serialization.Serializer
· 发序列化接口：org.apache.kafka.common.serialization.Deserializer

实现接口后，重点实现serialize和deserialize方法。
```

#### 1.5 分区器

```
· ProducerConfig.PARTITIONER_CLASS_CONFIG
· 自定义分区器，实现org.apache.kafka.clients.producer.Partitioner接口，并重写public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster)方法
```



### 2. 消费者

#### 2.1 消费者与消费者组的概念

#### 2.2 点对点模型与发布订阅模型

#### 2.3 核心参数方法

```
· bootstrap.servers: 用来指定连接Kafka集群所需的broker地址清单
· key.deserializer和value.deserializer: 反序列化参数
· group.id: 消费者所属消费组
· subscribe: 消息主题订阅，支持集合/标准正则表达式
· assign: 只订阅主题的某个分区
· enable.auto.commit: 自动提交位移量，默认为true
· auto.commit.interval.ms: 提交周期间隔，默认为5s
· auto.offset.reset: 消费者默认每次拉取消息的offset，即从什么位置开始拉取。有三个值可以选("latest","earliest","none")
```

#### 2.4 消费者提交位移

```
· 手工提交: enable.auto.commit配置为false
· 提交方式: commitSync(同步提交) & commitAsync(异步提交)
· 同步提交: 整体提交 & 分区提交
```

#### 2.5 消费者的在均衡

```Java
同一个消费者组中，新增了一个消费者后，Kafka会将分区从消费者中回收，在同一个消费者组中重新分配，就是在均衡。
可通过订阅主题时，添加监听器进行查看哪些分区分配到哪个消费者。如下：
consumer.subscribe(Collections.singletonList(Const.TOPIC_REBALANCE), new ConsumerRebalanceListener() {
	@Override
	public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        // 回收当前消费者的分区
		System.err.println("Revoked Partitions:" + partitions);
	}

	@Override
	public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
        // 分配至当前消费者的分区
		System.err.println("Assigned Partitions:" + partitions);
	}
});
```

#### 2.6 消费者多线程

```
· Kafka的生产者是线程安全的，Kafka的消费者是线程不安全的
· Kafka的消费者中定义了一个acquire方法用来检测是否只有一个线程在操作，如果有其他线程在操作则会抛出ConcurrentModificationException
· Kafka的消费者在执行所有动作时，都是先执行acquire方法检测是否线程安全
```

#### 2.6.1 消费者多线程模型实现思路

使分区与消费者一对一，消费者使用多线程启动。

```java
public class KafkaConsumerMt1 implements Runnable {

	private KafkaConsumer<String, String> consumer;
	
	private volatile boolean isRunning = true;
	
	private static AtomicInteger counter = new AtomicInteger(0);
	
	private String consumerName;
	
	public KafkaConsumerMt1(Properties properties, String topic) {
		this.consumer = new KafkaConsumer<>(properties);
		this.consumer.subscribe(Arrays.asList(topic));
		this.consumerName = "KafkaConsumerMt1-" + counter.getAndIncrement();
		System.err.println(this.consumerName + " started ");
	}
	
	@Override
	public void run() {
		try {
			while(isRunning) {
				//	包含所有topic下的所有消息内容
				ConsumerRecords<String, String> consumerRecords = consumer.poll(Duration.ofMillis(1000));
				for(TopicPartition topicPartition : consumerRecords.partitions()) {
//					String topic = topicPartition.topic();
					//	根据具体的topicPartition 去获取对应topicPartition下的数据集合
					List<ConsumerRecord<String, String>> partitionList = consumerRecords.records(topicPartition);
					int size = partitionList.size();
					for(int i = 0; i < size; i++) {
						ConsumerRecord<String, String> consumerRecord = partitionList.get(i);
						// do execute message
						String message = consumerRecord.value();
						long messageOffset = consumerRecord.offset();
						System.err.println("当前消费者："+ consumerName 
								+ ",消息内容：" + message 
								+ ", 消息的偏移量: " + messageOffset
								+ ", 当前线程：" + Thread.currentThread().getName());
					}
				}
			}
		} finally {
			if(consumer != null) {
				consumer.close();
			}
		}
	}

	public boolean isRunning() {
		return isRunning;
	}

	public void setRunning(boolean isRunning) {
		this.isRunning = isRunning;
	}

}
```

#### 2.6.2 消费者多线程模型实现思路

同一主题Topic下的所有分区消息，都由一个消费者(Master)负责拉取，放入队列中，真实消费者的线程池中的Handler去到对应分区队列中拉取消息并消费，将消费结果返回给消费者(Master)中的结果集队列中，再进行手工的提交consumer.commitSync()。

```

```

#### 2.7 消费者的重要参数

```
· fetch.min.bytes: 一次拉取最小数据量，默认是1B
· fetch.max.bytes: 一次拉取最大数据量，默认是50M
· max.partition.fetch.bytes: 一次fetch请求，从一个partition中取得的records最大的大小，默认为1M
· fetch.max.wait.ms: fetch请求发给broker后，在broker中可能会被阻塞的时长，默认为500
· max.poll.records: Consumer每次调用poll()时，去到的records最大的数，默认为500条
```



































